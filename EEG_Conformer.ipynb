{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kATWsTtKve3an751sulYk0cJijQ0nILK",
      "authorship_tag": "ABX9TyN1hn3Cbm4fIvdZh/ZqBttB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjunaid122/EEG_DEAP_Dataset/blob/main/EEG_Conformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x0pY2Qpw7x7z"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "EEG Conformer \n",
        "Convolutional Transformer for EEG decoding\n",
        "Couple CNN and Transformer in a concise manner with amazing results\n",
        "\"\"\"\n",
        "# remember to change paths\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "gpus = [0]\n",
        "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, gpus))\n",
        "import numpy as np\n",
        "import math\n",
        "import glob\n",
        "import random\n",
        "import itertools\n",
        "import datetime\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "import scipy.io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --force einops==0.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWU2IF-68Yqi",
        "outputId": "0025c57e-cbae-45f7-89ee-02e3ed3e5412"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops==0.4.1\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "import torch.autograd as autograd\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn.init as init\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "# from common_spatial_pattern import csp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.backends import cudnn\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "\n",
        "# writer = SummaryWriter('./TensorBoardX/')\n"
      ],
      "metadata": {
        "id": "mYa47DK38A0B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolution module\n",
        "# use conv to capture local features, instead of postion embedding.\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, emb_size=40):\n",
        "        # self.patch_size = patch_size\n",
        "        super().__init__()\n",
        "\n",
        "        self.shallownet = nn.Sequential(\n",
        "            nn.Conv2d(1, 40, (1, 25), (1, 1)),\n",
        "            nn.Conv2d(40, 40, (22, 1), (1, 1)),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 75), (1, 15)),  # pooling acts as slicing to obtain 'patch' along the time dimension as in ViT\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Conv2d(40, emb_size, (1, 1), stride=(1, 1)),  # transpose, conv could enhance fiting ability slightly\n",
        "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
        "        )"
      ],
      "metadata": {
        "id": "EshR_6Nd8eh4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x: Tensor) -> Tensor:\n",
        "        b, _, _, _ = x.shape\n",
        "        x = self.shallownet(x)\n",
        "        x = self.projection(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rtGOMCBL89V4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size, num_heads, dropout):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.keys = nn.Linear(emb_size, emb_size)\n",
        "        self.queries = nn.Linear(emb_size, emb_size)\n",
        "        self.values = nn.Linear(emb_size, emb_size)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)"
      ],
      "metadata": {
        "id": "Ax3e_EpC9Adj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
        "        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        values = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)  \n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "\n",
        "        scaling = self.emb_size ** (1 / 2)\n",
        "        att = F.softmax(energy / scaling, dim=-1)\n",
        "        att = self.att_drop(att)\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "spJQIi1f9EQo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        res = x\n",
        "        x = self.fn(x, **kwargs)\n",
        "        x += res\n",
        "        return x"
      ],
      "metadata": {
        "id": "ITmt6JSa9HQm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size, expansion, drop_p):\n",
        "        super().__init__(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "        )"
      ],
      "metadata": {
        "id": "u5Bv27kv9KKS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        return input*0.5*(1.0+torch.erf(input/math.sqrt(2.0)))"
      ],
      "metadata": {
        "id": "gBnu6mNW9Mi5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 num_heads=10,\n",
        "                 drop_p=0.5,\n",
        "                 forward_expansion=4,\n",
        "                 forward_drop_p=0.5):\n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                MultiHeadAttention(emb_size, num_heads, drop_p),\n",
        "                nn.Dropout(drop_p)\n",
        "            )),\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                FeedForwardBlock(\n",
        "                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                nn.Dropout(drop_p)\n",
        "            )\n",
        "            ))"
      ],
      "metadata": {
        "id": "Nx72cYZY9PmO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth, emb_size):\n",
        "        super().__init__(*[TransformerEncoderBlock(emb_size) for _ in range(depth)])"
      ],
      "metadata": {
        "id": "hBkYDSLY9SW6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, emb_size, n_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # global average pooling\n",
        "        self.clshead = nn.Sequential(\n",
        "            Reduce('b n e -> b e', reduction='mean'),\n",
        "            nn.LayerNorm(emb_size),\n",
        "            nn.Linear(emb_size, n_classes)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2440, 256),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 4)\n",
        "        )"
      ],
      "metadata": {
        "id": "AYKvi24c9VVb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "        x = x.contiguous().view(x.size(0), -1)\n",
        "        out = self.fc(x)\n",
        "        return x, out\n"
      ],
      "metadata": {
        "id": "lg6BbZ9N9XyB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conformer(nn.Sequential):\n",
        "    def __init__(self, emb_size=40, depth=6, n_classes=4, **kwargs):\n",
        "        super().__init__(\n",
        "\n",
        "            PatchEmbedding(emb_size),\n",
        "            TransformerEncoder(depth, emb_size),\n",
        "            ClassificationHead(emb_size, n_classes)\n",
        "        )"
      ],
      "metadata": {
        "id": "3oMGFja39bFV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExP():\n",
        "    def __init__(self, nsub):\n",
        "        super(ExP, self).__init__()\n",
        "        self.batch_size = 72\n",
        "        self.n_epochs = 2000\n",
        "        self.c_dim = 4\n",
        "        self.lr = 0.0002\n",
        "        self.b1 = 0.5\n",
        "        self.b2 = 0.999\n",
        "        self.dimension = (190, 50)\n",
        "        self.nSub = nsub\n",
        "\n",
        "        self.start_epoch = 0\n",
        "        self.root = '/content/drive/MyDrive/DEAP_DATASET/data_preprocessed_python/'\n",
        "\n",
        "        self.log_write = open(\"/content/drive/MyDrive/DEAP_DATASET/data_preprocessed_python/log_subject%d.txt\" % self.nSub, \"w\")\n",
        "\n",
        "\n",
        "        self.Tensor = torch.cuda.FloatTensor\n",
        "        self.LongTensor = torch.cuda.LongTensor\n",
        "\n",
        "        self.criterion_l1 = torch.nn.L1Loss().cuda()\n",
        "        self.criterion_l2 = torch.nn.MSELoss().cuda()\n",
        "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "        self.model = Conformer().cuda()\n",
        "        self.model = nn.DataParallel(self.model, device_ids=[i for i in range(len(gpus))])\n",
        "        self.model = self.model.cuda()\n",
        "        # summary(self.model, (1, 22, 1000))"
      ],
      "metadata": {
        "id": "b72Hyy589fv4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmentation and Reconstruction (S&R) data augmentation\n",
        "def interaug(self, timg, label):  \n",
        "        aug_data = []\n",
        "        aug_label = []\n",
        "        for cls4aug in range(4):\n",
        "            cls_idx = np.where(label == cls4aug + 1)\n",
        "            tmp_data = timg[cls_idx]\n",
        "            tmp_label = label[cls_idx]\n",
        "\n",
        "            tmp_aug_data = np.zeros((int(self.batch_size / 4), 1, 22, 1000))\n",
        "            for ri in range(int(self.batch_size / 4)):\n",
        "                for rj in range(8):\n",
        "                    rand_idx = np.random.randint(0, tmp_data.shape[0], 8)\n",
        "                    tmp_aug_data[ri, :, :, rj * 125:(rj + 1) * 125] = tmp_data[rand_idx[rj], :, :,\n",
        "                                                                      rj * 125:(rj + 1) * 125]\n",
        "\n",
        "            aug_data.append(tmp_aug_data)\n",
        "            aug_label.append(tmp_label[:int(self.batch_size / 4)])\n",
        "        aug_data = np.concatenate(aug_data)\n",
        "        aug_label = np.concatenate(aug_label)\n",
        "        aug_shuffle = np.random.permutation(len(aug_data))\n",
        "        aug_data = aug_data[aug_shuffle, :, :]\n",
        "        aug_label = aug_label[aug_shuffle]\n",
        "\n",
        "        aug_data = torch.from_numpy(aug_data).cuda()\n",
        "        aug_data = aug_data.float()\n",
        "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
        "        aug_label = aug_label.long()\n",
        "        return aug_data, aug_label"
      ],
      "metadata": {
        "id": "GENzy2O19nn1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_source_data(self):\n",
        "\n",
        "        # train data\n",
        "        self.total_data = scipy.io.loadmat(self.root + 'A0%dT.mat' % self.nSub)\n",
        "        self.train_data = self.total_data['data']\n",
        "        self.train_label = self.total_data['label']\n",
        "\n",
        "        self.train_data = np.transpose(self.train_data, (2, 1, 0))\n",
        "        self.train_data = np.expand_dims(self.train_data, axis=1)\n",
        "        self.train_label = np.transpose(self.train_label)\n",
        "\n",
        "        self.allData = self.train_data\n",
        "        self.allLabel = self.train_label[0]\n",
        "\n",
        "        shuffle_num = np.random.permutation(len(self.allData))\n",
        "        self.allData = self.allData[shuffle_num, :, :, :]\n",
        "        self.allLabel = self.allLabel[shuffle_num]\n",
        "\n",
        "        # test data\n",
        "        self.test_tmp = scipy.io.loadmat(self.root + 'A0%dE.mat' % self.nSub)\n",
        "        self.test_data = self.test_tmp['data']\n",
        "        self.test_label = self.test_tmp['label']\n",
        "\n",
        "        self.test_data = np.transpose(self.test_data, (2, 1, 0))\n",
        "        self.test_data = np.expand_dims(self.test_data, axis=1)\n",
        "        self.test_label = np.transpose(self.test_label)\n",
        "\n",
        "        self.testData = self.test_data\n",
        "        self.testLabel = self.test_label[0]\n",
        "\n",
        "\n",
        "        # standardize\n",
        "        target_mean = np.mean(self.allData)\n",
        "        target_std = np.std(self.allData)\n",
        "        self.allData = (self.allData - target_mean) / target_std\n",
        "        self.testData = (self.testData - target_mean) / target_std\n",
        "\n",
        "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
        "        return self.allData, self.allLabel, self.testData, self.testLabel"
      ],
      "metadata": {
        "id": "lsrMWEpz9wKb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(self):\n",
        "\n",
        "        img, label, test_data, test_label = self.get_source_data()\n",
        "\n",
        "        img = torch.from_numpy(img)\n",
        "        label = torch.from_numpy(label - 1)\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(img, label)\n",
        "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        test_data = torch.from_numpy(test_data)\n",
        "        test_label = torch.from_numpy(test_label - 1)\n",
        "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        # Optimizers\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
        "\n",
        "        test_data = Variable(test_data.type(self.Tensor))\n",
        "        test_label = Variable(test_label.type(self.LongTensor))\n",
        "\n",
        "        bestAcc = 0\n",
        "        averAcc = 0\n",
        "        num = 0\n",
        "        Y_true = 0\n",
        "        Y_pred = 0\n",
        "\n",
        "        # Train the cnn model\n",
        "        total_step = len(self.dataloader)\n",
        "        curr_lr = self.lr\n",
        "        for e in range(self.n_epochs):\n",
        "            # in_epoch = time.time()\n",
        "            self.model.train()\n",
        "            for i, (img, label) in enumerate(self.dataloader):\n",
        "\n",
        "                img = Variable(img.cuda().type(self.Tensor))\n",
        "                label = Variable(label.cuda().type(self.LongTensor))\n",
        "\n",
        "                # data augmentation\n",
        "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
        "                img = torch.cat((img, aug_data))\n",
        "                label = torch.cat((label, aug_label))\n",
        "\n",
        "\n",
        "                tok, outputs = self.model(img)\n",
        "\n",
        "                loss = self.criterion_cls(outputs, label) \n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                # out_epoch = time.time()\n",
        "\n",
        "\n",
        "            # test process\n",
        "            if (e + 1) % 1 == 0:\n",
        "                self.model.eval()\n",
        "                Tok, Cls = self.model(test_data)\n",
        "\n",
        "\n",
        "                loss_test = self.criterion_cls(Cls, test_label)\n",
        "                y_pred = torch.max(Cls, 1)[1]\n",
        "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
        "                train_pred = torch.max(outputs, 1)[1]\n",
        "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
        "\n",
        "                print('Epoch:', e,\n",
        "                      '  Train loss: %.6f' % loss.detach().cpu().numpy(),\n",
        "                      '  Test loss: %.6f' % loss_test.detach().cpu().numpy(),\n",
        "                      '  Train accuracy %.6f' % train_acc,\n",
        "                      '  Test accuracy is %.6f' % acc)\n",
        "\n",
        "                self.log_write.write(str(e) + \"    \" + str(acc) + \"\\n\")\n",
        "                num = num + 1\n",
        "                averAcc = averAcc + acc\n",
        "                if acc > bestAcc:\n",
        "                    bestAcc = acc\n",
        "                    Y_true = test_label\n",
        "                    Y_pred = y_pred\n",
        "\n",
        "\n",
        "        torch.save(self.model.module.state_dict(), 'model.pth')\n",
        "        averAcc = averAcc / num\n",
        "        print('The average accuracy is:', averAcc)\n",
        "        print('The best accuracy is:', bestAcc)\n",
        "        self.log_write.write('The average accuracy is: ' + str(averAcc) + \"\\n\")\n",
        "        self.log_write.write('The best accuracy is: ' + str(bestAcc) + \"\\n\")\n",
        "\n",
        "        return bestAcc, averAcc, Y_true, Y_pred\n",
        "        # writer.close()"
      ],
      "metadata": {
        "id": "k8upBKrH9zS3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    best = 0\n",
        "    aver = 0\n",
        "    result_write = open(\"/content/drive/MyDrive/DEAP_DATASET/data_preprocessed_python/sub_result.txt\", \"w\")\n",
        "\n",
        "    for i in range(9):\n",
        "        starttime = datetime.datetime.now()\n",
        "\n",
        "\n",
        "        seed_n = np.random.randint(2021)\n",
        "        print('seed is ' + str(seed_n))\n",
        "        random.seed(seed_n)\n",
        "        np.random.seed(seed_n)\n",
        "        torch.manual_seed(seed_n)\n",
        "        torch.cuda.manual_seed(seed_n)\n",
        "        torch.cuda.manual_seed_all(seed_n)\n",
        "\n",
        "\n",
        "        print('Subject %d' % (i+1))\n",
        "        exp = ExP(i + 1)\n",
        "\n",
        "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
        "        print('THE BEST ACCURACY IS ' + str(bestAcc))\n",
        "        result_write.write('Subject ' + str(i + 1) + ' : ' + 'Seed is: ' + str(seed_n) + \"\\n\")\n",
        "        result_write.write('Subject ' + str(i + 1) + ' : ' + 'The best accuracy is: ' + str(bestAcc) + \"\\n\")\n",
        "        result_write.write('Subject ' + str(i + 1) + ' : ' + 'The average accuracy is: ' + str(averAcc) + \"\\n\")\n",
        "\n",
        "        endtime = datetime.datetime.now()\n",
        "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
        "        best = best + bestAcc\n",
        "        aver = aver + averAcc\n",
        "        if i == 0:\n",
        "            yt = Y_true\n",
        "            yp = Y_pred\n",
        "        else:\n",
        "            yt = torch.cat((yt, Y_true))\n",
        "            yp = torch.cat((yp, Y_pred))\n",
        "\n",
        "\n",
        "    best = best / 9\n",
        "    aver = aver / 9\n",
        "\n",
        "    result_write.write('**The average Best accuracy is: ' + str(best) + \"\\n\")\n",
        "    result_write.write('The average Aver accuracy is: ' + str(aver) + \"\\n\")\n",
        "    result_write.close()"
      ],
      "metadata": {
        "id": "XXOugr2P913X"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crmbNOx1aKuD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}